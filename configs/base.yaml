# -*- coding: utf-8 -*-
# 基础参数配置

data:
  root_dir: "./data/low_frequency_interatation/"
  train_dir: "./data/low_frequency_interatation/train_data"
  test_dir: "./data/low_frequency_interatation/test_data"
  global_data_keys: ['H', 'h', 'tho', 'kappa', 'sigma','overlap']
  subdomain_data_keys: ['number_of_eigval_in_found', 'blk_size',
  'm_l', 'size_of_weight_function',"weight_function"]
  batch_size: 1024


model:
  output_dim: 20
  optim: "Adam"
  lr:  0.001
  scheduler: "MultiStepLR"
  k_list: 10
  if_save_model: false
  save_path: "./logs"
scheduler:
  MultiStepLR:
    milestones: [10, 20]
    gamma: 0.5
network:
  d_model: 32
query_network:
  network: "MLP"
  MLP:
    #output_dim: {{"network.d_model"}}
    input_dim: 2
    layer_number: 2
    layer_size: [16, 16]
geometrial_network:
  network: "MLP"
  keys: ['H', 'h','overlap','m_l']
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size: [16,16]

preditor_network:
  network: "MLP"
  #keys: ["kappa", "sigma"]
  MLP:
    layer_number: 2
    layer_size: [16,16]

physics_network:
  network: "MLP"
  keys: ["kappa", "sigma"]
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size: [16,16]
attention_network:
  network: "MultiheadAttention"
  MultiheadAttention:
    num_heads: 1
    batch_first: True
weight_network:
  network: "AdaptivePoolEncoder"
  keys: ["weight_function"]
  AdaptivePoolEncoder:
    #经过初步测试16-64是较好的参数组合
    feature_dim: 16
    output_dim: 64




training:
  epochs: 41
  batch_size: 1024

Experimental_args: ["model.output_dim"]
Experimental_purpose: "通过减少类别测试数据分布是否是有效的"
logging:
  log_dir: "./logs"
  level: "INFO"