#!/share/home/liziyi/opt/Python-3.10.0/bin/python3
import os
import sys
import json
import random
import math
from easy_tool import *
cur_path = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(cur_path, ".."))

from bsub_template import *
if_need_mpi=True#是否需要进行并行运算
if_need_make_sure=False#是否需要在提交程序时输入y进行确认
#exec = "lshape"
exec = "2level"
# np = 4
prefix = "pure_bdrext"
ptile = 36
#subdir = "lshape"
subdir = None
#确定数据文件的输出路劲
data_file_dir="/share/home/yangchenxi/pddm/helmholtz/new_result"
data_file_module_name="data"
data_file_suffix =".h5"
#data_file_add=generate_file_name(data_file_dir,data_file_module_name,data_file_suffix)
#print("测试文件地址：",data_file_add)

#设置数据，部分数据随机生成：
# frequence_inf=1
# frequence_sup=15
frequence_inf=16
frequence_sup=30
frequence =random.randint(frequence_inf,frequence_sup)
# frequence=40

kappa=frequence*math.pi
beta_inf=0.5
beta_sup=0.6
beta=random.uniform(beta_inf,beta_sup)
# beta=0.6
size=1.0
order=1
h_k_order=-1-1/(2*order)
# print("kappa:",kappa)
#h_k_order=-1.5
# print("h^order",h_k_order)
# print(size/kappa)
h=(size/kappa)**(-h_k_order)
# print("h:",h)
npart=find_min_m(s=size,v=h)
H=(size/kappa)**(beta)
# print("H:",H)
Npart=find_min_m(s=size,v=H)
# Noverlap=random.randint(1,3)
Noverlap=1
shift_inf=0.1
shift_sup=2.0
shift=random.uniform(shift_inf,shift_sup)
# shift=1.0

#测试
# frequence=16

# npart=8
# Npart=4
# order=1
# Noverlap=2
# #shift
# shift=1.6980503075205

# np = Npart**2
#在2level中的赋值说明
    # kappa = kappa == 1.0 ? freq * M_PI : kappa;
    # sigma = p >= 0 ? pow(kappa, p) : 0.0;
    # nx = ny = nz = n;
    # sx = sy = sz = s;
    # nparts = pow(N, Dim);
    # overlap = overlap == -1 ? round(delta * (double)n / (double)N) : overlap;
    # overlap = overlap == 0 ? 1 : overlap;
    # cgs = cgs == -1 ? N : cgs;
#Npart

np=Npart**2
options = {
    "frequence": frequence,
    #  "kappa": 18.5,
    "npart": npart,
    "Npart": Npart,
    "order": order,
    "Noverlap": Noverlap,#对应overlap
    #  "overlap": 0.25,
    "shift": shift,
    #"corr": "adef2",
    "corr":"ad",
    #"power":2.0,
    #  "cgs": 64,
    #"nev": 45,
    "nev":-1,
    #"data_file_add":data_file_add,#测试不成功，提交到集群即使在串行的情况下仍然不成功暂时考虑在2level中给定
#     "data_file_dir":data_file_dir,
# "data_file_module_name":data_file_module_name,
    #  "tol": 0.0387,
}
print(options)
if if_need_mpi:
    cmd, file = getCommand(np, exec, options)
else:
    cmd,file=getCommand_without_mpi(exec,options)
if subdir is not None:
    result = os.path.join(".", "result", exec, subdir)
else:
    result = os.path.join(".", "result", exec)
print(cmd)
while True:
    if if_need_make_sure:
        yn = input("Ready to bsub command: " + cmd + " ? ([y]/n)")
    else:
        yn="y"
    if yn == "y" or yn == "":
        os.makedirs(result, exist_ok=True)
        file = os.path.join(result, prefix + file + ".out")

        lsf_json["resource"]["numTasks"] = np
        lsf_json["resource"]["resReq"] = "span[ptile=" + str(ptile) + "]"
        lsf_json["properties"]["jobDescription"] = exec
        lsf_json["command"] = precmd + cmd + " 1>" + file + " 2>&1"

        print(json.dumps(lsf_json, indent=4), file=open("bsub.json", "w"))
        os.system("bsub -json bsub.json")
        os.remove("bsub.json")
        break
    elif yn == "n":
        exit()
    else:
        print('Must enter y("enter") or n!')



# while True:
#     yn = input("Ready to bsub command: " + cmd + " ? ([y]/n)")
#     if yn == "y" or yn == "":
#         os.makedirs(result, exist_ok=True)
#         file = os.path.join(result, prefix + file + ".out")

#         lsf_json["resource"]["numTasks"] = np
#         lsf_json["resource"]["resReq"] = "span[ptile=" + str(ptile) + "]"
#         lsf_json["properties"]["jobDescription"] = exec
#         lsf_json["command"] = precmd + cmd + " 1>" + file + " 2>&1"

#         print(json.dumps(lsf_json, indent=4), file=open("bsub.json", "w"))
#         os.system("bsub -json bsub.json")
#         os.remove("bsub.json")
#         break
#     elif yn == "n":
#         exit()
#     else:
#         print('Must enter y("enter") or n!')
