data:
  root_dir: ./data/low_frequency_interatation/
  train_dir: ./data/low_frequency_interatation/train_data
  test_dir: ./data/low_frequency_interatation/test_data
  global_data_keys:
  - H
  - h
  - tho
  - kappa
  - sigma
  - overlap
  subdomain_data_keys:
  - number_of_eigval_in_found
  - blk_size
  - m_l
  - size_of_weight_function
  - weight_function_grid
  - x_max
  - x_min
  - y_min
  - y_max
  batch_size: 1024
model:
  output_dim: 20
  optim: Adam
  lr: 0.0001
  scheduler: MultiStepLR
  loss: cross_entropy_loss
  k_list: 20
  if_save_model: false
  save_path: ./logs
  tho_generator: Tho_generator_network
scheduler:
  MultiStepLR:
    milestones:
    - 10
    - 20
    gamma: 0.5
loss:
  cross_entropy_loss:
    label_smoothing: 0.2
    if_update_weights: false
  cross_entropy_loss_with_mse:
    label_smoothing: 0.2
    alpha: 10.0
    if_update_weights: false
query_network:
  network: MLP
  MLP:
    input_dim: 2
    layer_number: 2
    layer_size:
    - 16
    - 16
geometrial_network:
  network: MLP
  keys:
  - H
  - h
  - overlap
  - m_l
  - x_max
  - x_min
  - y_min
  - y_max
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size:
    - 16
    - 16
preditor_network:
  network: MLP
  MLP:
    layer_number: 2
    layer_size:
    - 64
    - 64
    act_fun: tanh
physics_network:
  network: MLP
  keys:
  - kappa
  - sigma
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size:
    - 64
    - 64
attention_network:
  network: MultiheadAttention
  MultiheadAttention:
    num_heads: 1
    batch_first: true
weight_network:
  network: AdaptiveCNN
  keys:
  - weight_function_grid
  AdaptivePoolEncoder:
    feature_dim: 16
    output_dim: 64
  AdaptiveCNN:
    input_channels: 1
    output_dim: 64
    initial_cnn_arg:
      layer_number: 4
      kernel_size:
      - 3
      - 3
      - 3
      - 3
      channel_size:
      - 8
      - 16
      - 32
      - 32
      padding_size:
      - 1
      - 1
      - 1
      - 1
      if_use_batchNorm:
      - true
      - true
      - true
      - true
      act_fun: relu
      if_pooling:
      - true
      - true
      - false
      - false
      pooling_model: max
      pooling_size:
      - 2
      - 2
      - 2
      - 2
    final_cnn_arg:
      layer_number: 3
      kernel_size:
      - 3
      - 3
      - 3
      channel_size:
      - 64
      - 64
      - 32
      padding_size:
      - 1
      - 1
      - 1
      - 1
      if_use_batchNorm:
      - true
      - true
      - true
      act_fun: relu
      if_pooling:
      - true
      - true
      - false
      pooling_model: max
      pooling_size:
      - 2
      - 2
      - 2
    adaptive_layer_arg:
      kernel_size:
      - 3
      channel_size:
      - 64
      padding_size:
      - 1
      if_use_batchNorm:
      - true
      act_fun: relu
    global_pool_size: 10
tho_generator:
  Tho_generator_uniform_xiugai:
    beta: -0.4
    low_rate: 0.75
    up_rate: 2.0
    mean_rate: 0.25
  Tho_generator_network:
    network: MLP
    model_pth: ./tho_generator_model_pth/20250513_123300model_best_kl.pth
    MLP:
      input_dim: 32
      output_dim: 1
      layer_number: 4
      layer_size:
      - 32
      - 64
      - 128
      - 32
      act_fun: sigmoid
      pow_k: 1
training:
  epochs: 40
  batch_size: 1024
Experimental_args:
- tho_generator.Tho_generator_uniform_xiugai.mean_rate
- tho_generator.Tho_generator_uniform_xiugai.up_rate
Experimental_purpose: 测试代码的通畅性
logging:
  log_dir: ./logs
  level: INFO
model_pth: None
model_config: None
model_modify_config: None
