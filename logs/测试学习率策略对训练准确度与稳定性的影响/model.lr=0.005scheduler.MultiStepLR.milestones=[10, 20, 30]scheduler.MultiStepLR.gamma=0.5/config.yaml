data:
  root_dir: ./data/low_frequency_interatation/
  train_dir: ./data/low_frequency_interatation/train_data
  test_dir: ./data/low_frequency_interatation/test_data
  global_data_keys:
  - H
  - h
  - tho
  - kappa
  - sigma
  - overlap
  subdomain_data_keys:
  - number_of_eigval_in_found
  - blk_size
  - m_l
  - size_of_weight_function
  - weight_function
  batch_size: 1024
model:
  output_dim: 20
  optim: Adam
  lr: 0.005
  scheduler: MultiStepLR
  k_list: 10
  if_save_model: false
  save_path: ./logs
scheduler:
  MultiStepLR:
    milestones:
    - 10
    - 20
    - 30
    gamma: 0.5
network:
  d_model: 32
query_network:
  network: MLP
  MLP:
    input_dim: 2
    layer_number: 2
    layer_size:
    - 16
    - 16
geometrial_network:
  network: MLP
  keys:
  - H
  - h
  - overlap
  - m_l
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size:
    - 16
    - 16
preditor_network:
  network: MLP
  MLP:
    layer_number: 2
    layer_size:
    - 16
    - 16
physics_network:
  network: MLP
  keys:
  - kappa
  - sigma
  MLP:
    output_dim: 32
    layer_number: 2
    layer_size:
    - 16
    - 16
attention_network:
  network: MultiheadAttention
  MultiheadAttention:
    num_heads: 1
    batch_first: true
weight_network:
  network: AdaptivePoolEncoder
  keys:
  - weight_function
  AdaptivePoolEncoder:
    feature_dim: 8
    output_dim: 32
training:
  epochs: 60
  batch_size: 1024
Experimental_args:
- model.lr
- scheduler.MultiStepLR.milestones
- scheduler.MultiStepLR.gamma
Experimental_purpose: 测试学习率策略对训练准确度与稳定性的影响
logging:
  log_dir: ./logs
  level: INFO
config: ./configs/base.yaml
